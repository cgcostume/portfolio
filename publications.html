<!doctype html><html lang="en"><head><meta http-equiv="x-ua-compatible" content="ie=edge"><meta charset="utf-8"><meta name="viewport" content="width=device-widthinitial-scale=1"><title>Daniel Limberger</title><meta name="description" content="ToDo"><meta name="robots" content="index, follow"><link rel="stylesheet" href="/glightbox.min.css"><link rel="stylesheet" href="/styles.css"><link rel="shortcut icon" href="/favicon.ico"><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"><link rel="icon" type="image/png" sizes="48x48" href="/favicon-48x48.png"><noscript><style class="js-only">{ display: none; }</style></noscript></head><body id="page-top" data-spy="scroll"><section class="container" id="publications"><div class="row text-center"><div class="col-12"><h2>All <strong>Publications</strong></h2><p><a class="text-secondary" href="/index.html#publications">by <strong>Daniel Limberger</strong></a></p><p class="pt-0">Research Profiles:&ensp;<a href="https://orcid.org/0000-0002-9111-4809">ORCID</a><br class="d-inline d-sm-none"><span class="d-none d-sm-inline">&ensp;|&ensp;</span><a href="https://www.researchgate.net/profile/Daniel_Limberger">Research Gate</a><br class="d-inline d-sm-none"><span class="d-none d-sm-inline">&ensp;|&ensp;</span><a href="https://scholar.google.de/citations?user=58R1TH4AAAAJ">Google Scholar</a></p></div></div><div class="row" id="2022-web3d-scatter-plot-density"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-web3d-scatter-plot-density.webp" alt="Thumbnail of Hardware-accelerated Rendering of Web-based 3D Scatter Plots with Projected Density Fields and Embedded Controls"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Hardware-accelerated Rendering of Web-based 3D Scatter Plots with Projected Density Fields and Embedded Controls</h3><p></p>Proc. ACM Int. Conf. on Web3D Technology (Web3D), 2022,&nbsp;<a href="https://web3d.siggraph.org/awards/">Best Paper</a><p><small>Lukas Wagner, Daniel Limberger, Willy Scheibel, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-web3d-scatter-plot-density">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-web3d-scatter-plot-density">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3564533.3564566">DOI</a>&ensp;|&ensp;<a href="https://dl.acm.org/doi/pdf/10.1145/3564533.3564566">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-web3d-scatter-plot-density"><p>3D scatter plots depicting massive data suffer from occlusion, which makes it difficult to get an overview and perceive structure. This paper presents a technique that facilitates the comprehension of heavily occluded 3D scatter plots. Data points are projected to axial planes, creating x-ray-like 2D views that support the user in analyzing the data's density and layout. We showcase our open-source web application with a hardware-accelerated rendering component written in WebGL. It allows for interactive interaction, filtering, and navigation with datasets up to hundreds of thousands of nodes. The implementation is detailed and discussed with respect to challenges posed by API and performance limitations.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-web3d-scatter-plot-density"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="wagner2022-scatter-plot-density.bib" href="/bibliography/wagner2022-scatter-plot-density.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-web3d-scatter-plot-density" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-web3d-scatter-plot-density">@inproceedings{wagner2022-scatter-plot-density,
  author = {Wagner, Lukas and Limberger, Daniel and Scheibel, Willy and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Hardware-accelerated Rendering of Web-based 3D Scatter Plots with Projected Density Fields and Embedded Controls},
  booktitle = {Proceedings of the 27th International Conference on 3D Web Technology},
  year = {2022},
  series = {Web3D~'22},
  publisher = {ACM},
  doi = {10.1145/3564533.3564566},
  isbn = {978-1-450399-14-2},
}
</pre></div></div></div></div><div class="row" id="2022-eurocarto-pointcloud-cartography"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-eurocarto-pointcloud-cartography.webp" alt="Thumbnail of Non-Photorealistic Rendering of Point Clouds for Cartographic Visualization"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Non-Photorealistic Rendering of Point Clouds for Cartographic Visualization</h3><p></p>Extended Abstracts of Proc. ICA European Symp. on Cartography (EuroCarto), 2022<p><small>Ole Wegen, Jürgen Döllner, Ronja Wagner, Daniel Limberger, Rico Richter, and Matthias Trapp</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-eurocarto-pointcloud-cartography">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-eurocarto-pointcloud-cartography">BibTeX</a>&ensp;|&ensp;<a href="https://hpi.de/doellner/people/daniel-limberger/Document/matthias.trapp/EuroCarto-2022.Non-Photorealistic%20Rendering%20of%203D%20Point%20Clouds%20for%20Cartographic%20Visualization.pdf/1e5aa9c3f0251ef03d1d408aa0b06137.html?cHash=755590e0e12cd9e6d54660a459d6d6e5">Extended Abstract</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-eurocarto-pointcloud-cartography"><p>We present an approach for real-time non-photorealistic rendering (NPR) of 3D point clouds that provides a general-purpose component for their cartographic visualization. For a given 3D point cloud, per-point attributes are derived in the preprocessing phase, e.g., for geometric, semantic, and instance information. The point cloud thus attributed is then segmented into point clusters according to thematic or semantic criteria. Different NPR styles configured by style descriptors can be bound to this information, i.e., the NPR style is parameterized by the point attributes found in the clusters. The approach demonstrates that NPR applied to an enriched, clustered point cloud enables a generalized, abstract, and graphically styled visualization without the need to derive intermediate 3D representations. We have implemented, as a proof-of-concept, several styles and mappings typically required for cartographic 3D visualizations. Figure 1 shows an example of tree detection and its NPR depiction.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-eurocarto-pointcloud-cartography"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="wegen2022-pointcloud-cartography.bib" href="/bibliography/wegen2022-pointcloud-cartography.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-eurocarto-pointcloud-cartography" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-eurocarto-pointcloud-cartography">@inproceedings{wegen2022-pointcloud-cartography,
  author = {Wegen, Ole and D{\&quot;o}llner, J{\&quot;u}rgen and Wagner, Ronja and Limberger, Daniel and Richter, Rico and Trapp, Matthias},
  title = {Non-Photorealistic Rendering of Point Clouds for Cartographic Visualization},
  booktitle = {Extended Abstracts of Proceedings of the 1st ICA European Symposium on Cartography},
  year = {2022},
  series = {EuroCarto~'22},
  publisher = {ICA},
}
</pre></div></div></div></div><div class="row" id="2022-vinci-topicmodel-benchmark"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-vinci-topicmodel-benchmark.webp" alt="Thumbnail of A Benchmark for the Use of Topic Models for Text Visualization Tasks"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>A Benchmark for the Use of Topic Models for Text Visualization Tasks</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2022<p><small>Daniel Atzberger, Tim Cech, Willy Scheibel, Daniel Limberger, Jürgen Döllner, and Matthias Trapp</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-vinci-topicmodel-benchmark">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-vinci-topicmodel-benchmark">BibTeX</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-vinci-topicmodel-benchmark"><p>Based on the assumption that semantic relatedness between documents is reflected in the distribution of the vocabulary, topic models are a widely used technique for different analysis tasks. Their application results in concepts, the so-called topics, and a high-dimensional description of the documents. For visualization tasks, they can further be projected onto a lower-dimensional space using a dimension reduction technique. Though the quality of the resulting scatter plot mainly depends on the chosen layout technique and the choice of its hyperparameters, it is unclear which particular combinations of topic models and dimension reduction techniques are suitable for displaying the semantic relatedness between the documents. In this work, we propose a benchmark comprising various datasets, layout techniques, and quality metrics for conducting an empirical study on different such layout algorithms.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-vinci-topicmodel-benchmark"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2022-topicmodel-benchmark.bib" href="/bibliography/atzberger2022-topicmodel-benchmark.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-vinci-topicmodel-benchmark" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-vinci-topicmodel-benchmark">@InProceedings{atzberger2022-topicmodel-benchmark,
  author    = {Atzberger, Daniel and Cech, Tim and Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen and Trapp, Matthias},
  title     = {A Benchmark for the Use of Topic Models for Text Visualization Tasks},
  booktitle = {Proceedings of the 15th International Symposium on Visual Information Communication and Interaction},
  year      = {2022},
  series    = {VINCI~'22},
  publisher = {ACM},
}
</pre></div></div></div></div><div class="row" id="2022-enase-mining-expertise"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-enase-mining-expertise.webp" alt="Thumbnail of Mining Developer Expertise from Bug Tracking Systems using the Author-Topic Model"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Mining Developer Expertise from Bug Tracking Systems using the Author-Topic Model</h3><p></p>Proc. Int. Conf. on Evaluation of Novel Approaches to Software Engineering (ENASE), 2022,&nbsp;<a href="https://enase.scitevents.org/PreviousAwards.aspx?y=2023">Best Student Paper</a><p><small>Daniel Atzberger, Jonathan Schneider, Willy Scheibel, Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-enase-mining-expertise">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-enase-mining-expertise">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0011045100003176">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy-Scheibel/publication/360230384/inline/jsViewer/626ba74705d79a3968aa8968">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-enase-mining-expertise"><p>During the software development process, software defects, so-called bugs, are captured in a semi-structured manner in a bug tracking system using textual components and categorical features. It is the task of the triage owner to assign open bugs to developers with the required skills and expertise. This task, known as bug triaging, requires in-depth knowledge about a developer's skills. Various machine learning techniques have been proposed to automate this task, most of these approaches apply topic models, especially Latent Dirichlet Allocation, for mining the textual components of bug reports. However, none of the proposed approaches explicitly models a developer's expertise. In most cases, these algorithms are treated as a black box, as they allow no explanation about their recommendation. In this work, we show how the Author-Topic Model, a variant of Latent Dirichlet Allocation, can be used to capture a developer's expertise in the latent topics of a corpus of bug reports from the model itself. Furthermore, we present three novel bug triaging techniques based on the Author-Topic Model. We compare our approach against a baseline model, that is based on Latent Dirichlet Allocation, on a dataset of 18269 bug reports from the Mozilla Firefox project collected between July 1999 to June 2016. The results show that the Author-Topic Model can outperform the baseline approach in terms of the Mean Reciprocal Rank.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-enase-mining-expertise"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2022-mining-expertise.bib" href="/bibliography/atzberger2022-mining-expertise.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-enase-mining-expertise" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-enase-mining-expertise">@inproceedings{atzberger2022-mining-expertise,
  author = {Atzberger, Daniel and Schneider, Jonathan and Scheibel, Willy and Limberger, Daniel and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Mining Developer Expertise from Bug Tracking Systems using the Author-Topic Model},
  booktitle = {Proceedings of the 17th International Conference on Evaluation of Novel Approaches to Software Engineering - ENASE},
  year = {2022},
  series = {ENASE~'22},
  publisher = {SciTePress},
  organization = {INSTICC},
  pages = {107--118},
  doi = {10.5220/0011045100003176},
  isbn = {978-9-897585-68-5},
}
</pre></div></div></div></div><div class="row" id="2022-enase-downstream-mining"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-enase-downstream-mining.webp" alt="Thumbnail of Augmenting Library Development by Mining Usage Data from Downstream Dependencies"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Augmenting Library Development by Mining Usage Data from Downstream Dependencies</h3><p></p>Proc. Int. Conf. on Evaluation of Novel Approaches to Software Engineering (ENASE), 2022<p><small>Christoph Thiede, Willy Scheibel, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-enase-downstream-mining">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-enase-downstream-mining">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0011093700003176">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy-Scheibel/publication/360231022/inline/jsViewer/626ba510bfd24037e9dd1eee">Paper</a>&ensp;|&ensp;<a href="https://github.com/LinqLover/downstream-repository-mining">Project Page</a>&ensp;|&ensp;<a href="https://doi.org/10.5281/zenodo.6338060">Sources</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-enase-downstream-mining"><p>In the dependency graph of a software ecosystem, downstream dependencies are the nodes that depend on a package. Apart from end-user APIs, these dependencies make up the bulk of a library's usage for most packages. Other than for upstream dependencies, tools that provide individual package developers with this kind of information rarely exist to date. This paper proposes methods for (1) efficiently gathering downstream dependencies of a single package and (2) extracting usage samples from them using a static type analyzer. It also presents a tool that allows developers of \emph{npm} packages to explore the aggregated usage data directly in their IDE, i.e., Visual Studio Code, in an interactive and context-sensitive way. The tool exposes which other packages rely on specific functions and, more interestingly, why and how the package's functions are used. This can help prioritize and steer development and uncover unexpected usage patterns, inappropriate function signatures, or misleading interface design. Our methods return over 8000 dependencies for popular packages with an average precision of \SI{98.7}{\percent} and \SI{68.4}{\percent}, respectively, but tend to exclude unpopular dependencies. Usage pattern extraction is very precise but not easily available for repositories with complex build configurations or metaprogramming patterns. We show that usage data from downstream dependency repositories is a promising and diverse source of information for mining software repositories and that our approach supports package developers in maintain their APIs.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-enase-downstream-mining"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="thiede2022-downstream-mining.bib" href="/bibliography/thiede2022-downstream-mining.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-enase-downstream-mining" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-enase-downstream-mining">@inproceedings{thiede2022-downstream-mining,
  author = {Thiede, Christoph and Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Augmenting Library Development by Mining Usage Data from Downstream Dependencies},
  booktitle = {Proceedings of the 17th International Conference on Evaluation of Novel Approaches to Software Engineering - ENASE},
  year = {2022},
  series = {ENASE~'22},
  publisher = {SciTePress},
  organization = {INSTICC},
  pages = {221--232},
  doi = {10.5220/0011093700003176},
  isbn = {978-9-897585-68-5},
}
</pre></div></div></div></div><div class="row" id="2022-grapp-pointcloud-stylization"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-grapp-pointcloud-stylization.webp" alt="Thumbnail of A Non-Photorealistic Rendering Technique for Art-directed Hatching of 3D Point Clouds"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>A Non-Photorealistic Rendering Technique for Art-directed Hatching of 3D Point Clouds</h3><p></p>Proc. Int. Conf. on Computer Graphics Theory and Applications (GRAPP), 2022<p><small>Ronja Wagner, Ole Wegen, Daniel Limberger, Jürgen Döllner, and Matthias Trapp</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-grapp-pointcloud-stylization">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-grapp-pointcloud-stylization">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0010849500003124">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Matthias-Trapp-2/publication/358523901/inline/jsViewer/62061b63cf7c2349ca08c7fb">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel-Limberger/publication/358850452_A_Non-Photorealistic_Rendering_Technique_for_Art-directed_Hatching_of_3D_Point_Clouds/data/6218c22f6738db292ac68599/2022-01-28-Wagner-2022-NPR-for-3D-Point-Clouds-Slides-GRAPP.pdf">Slides</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-grapp-pointcloud-stylization"><p>Point clouds or point-based geometry of varying density can nowadays be easily acquired using LiDAR cameras or modern smartphones with LiDAR sensors. We demonstrate how this data can be used directly to create novel artistic digital content using Non-Photorealistic Rendering techniques. We introduce a GPU-based technique for art-directable NPR rendering of 3D point clouds at interactive frame-rates. The technique uses either a subset or all of the points to generate oriented, sketchy strokes by taking local curvature and normal information into account. It uses X-Toon textures as part of its parameterization, supports hatching and cross hatching, and is inherently temporal coherent with respect to virtual camera movements. This introduces significant artistic freedom that is underlined by our results, which show that a variety of different sketchy styles such as colored crayons, pencil, pointillism, wax crayons, blue print, and chalk-drawings can be achieved on a wide spectrum of point clouds, i.e., covering 3D polygonal meshes as well as iPad-based LiDAR scans.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-grapp-pointcloud-stylization"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="wagner2022-pointcloud-stylization.bib" href="/bibliography/wagner2022-pointcloud-stylization.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-grapp-pointcloud-stylization" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-grapp-pointcloud-stylization">@inproceedings{wagner2022-pointcloud-stylization,
  author = {Wagner, Ronja and Wegen, Ole and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen and Trapp, Matthias},
  title = {A Non-Photorealistic Rendering Technique for Art-directed Hatching of 3D Point Clouds},
  booktitle = {Proceedings of the 17th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2022},
  series = {GRAPP~'22},
  publisher = {SciTePress},
  pages = {220-227},
  doi = {10.5220/0010849500003124},
  isbn = {978-9-897585-55-5},
}
</pre></div></div></div></div><div class="row" id="2022-ivapp-knowhow-map"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2022-ivapp-knowhow-map.webp" alt="Thumbnail of Visualization of Knowledge Distribution across Development Teams using 2.5D Semantic Software Maps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Visualization of Knowledge Distribution across Development Teams using 2.5D Semantic Software Maps</h3><p></p>Proc. Int. Conf. on Information Visualization Theory and Applications (IVAPP), 2022<p><small>Daniel Atzberger, Tim Cech, Adrian Jobst, Willy Scheibel, Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2022-ivapp-knowhow-map">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2022-ivapp-knowhow-map">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0010991100003124">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Matthias-Trapp-2/publication/358523984/inline/jsViewer/62061c62afa8884cabd8675c">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2022-ivapp-knowhow-map"><p>In order to detect software risks at an early stage, various software visualization techniques have been developed for monitoring the structure, behaviour, or the underlying development process of software. One of greatest risks for any IT organization consists in an inappropriate distribution of knowledge among its developers, as a projects' success mainly depends on assigning tasks to developers with the required skills and expertise. In this work, we address this problem by proposing a novel Visual Analytics framework for mining and visualizing the expertise of developers based on their source code activities. Under the assumption that a developer's knowledge about code is represented directly through comments and the choice of identifier names, we generate a 2D layout using Latent Dirichlet Allocation together with Multidimensional Scaling on the commit history, thus displaying the semantic relatedness between developers. In order to capture a developer's expertise in a concept, we utilize Labeled LDA trained on a corpus of Open Source projects. By mapping aspects related to skills onto the visual variables of 3D glyphs, we generate a 2.5D Visualization, we call KnowhowMap. We exemplify this approach with an interactive prototype that enables users to analyze the distribution of skills and expertise in an explorative way.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2022-ivapp-knowhow-map"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2022-knowhow-map.bib" href="/bibliography/atzberger2022-knowhow-map.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2022-ivapp-knowhow-map" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2022-ivapp-knowhow-map">@inproceedings{atzberger2022-knowhow-map,
  author = {Atzberger, Daniel and Cech, Tim and Jobst, Adrian and Scheibel, Willy and Limberger, Daniel and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Visualization of Knowledge Distribution across Development Teams using 2.5D Semantic Software Maps},
  booktitle = {Proceedings of the 17th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - IVAPP},
  year = {2022},
  series = {IVAPP~'22},
  publisher = {SciTePress},
  pages = {210--217},
  doi = {10.5220/0010991100003124},
  isbn = {978-9-897585-55-5},
}
</pre></div></div></div></div><div class="row" id="2021-web3d-tumor-segmentation"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2021-web3d-tumor-segmentation.webp" alt="Thumbnail of Interactive Volumetric Region Growing for Brain Tumor Segmentation on MRI using WebGL"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Interactive Volumetric Region Growing for Brain Tumor Segmentation on MRI using WebGL</h3><p></p>Proc. ACM Int. Conf. on Web3D Technology (Web3D), 2021<p><small>Jonas Kordt, Paul Brachmann, Daniel Limberger, and Christoph Lippert</small></p><p><a data-bs-toggle="collapse" href="#abstract-2021-web3d-tumor-segmentation">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2021-web3d-tumor-segmentation">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3485444.3487640">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Jonas_Kordt/publication/356974519/inline/jsViewer/61bc6f3063bbd932429c6269">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2021-web3d-tumor-segmentation"><p>Volumetric segmentation of medical images is an essential tool in treatment planning and many longitudinal studies. While machine learning approaches promise to fully automate it, they most often still depend on manually labeled training data. We thus present a GPU-based volumetric region growing approach for semi-automatic brain tumor segmentation that can be interactively tuned. Additionally, we propose multidimensional transfer functions for ray tracing that allow users to judge the quality of the grown region. Our implementation produces a full brain tumor segmentation within a few milliseconds on consumer hardware. The visualization uses adaptive resolution scaling and progressive, asynchronous shading computation to maintain a stable 60 Hz refresh rate.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2021-web3d-tumor-segmentation"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="kordt2021-tumor-segmentation.bib" href="/bibliography/kordt2021-tumor-segmentation.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2021-web3d-tumor-segmentation" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2021-web3d-tumor-segmentation">@inproceedings{kordt2021-tumor-segmentation,
  author = {Kordt, Jonas and Brachmann, Paul and Limberger, Daniel and Lippert, Christoph},
  title = {Interactive Volumetric Region Growing for Brain Tumor Segmentation on MRI Using WebGL},
  booktitle = {Proceedings of the 26th International Conference on 3D Web Technology},
  year = {2021},
  series = {Web3D~'21},
  publisher = {ACM},
  pages = {2:1--8},
  doi = {10.1145/3485444.3487640},
  isbn = {978-1-450390-95-8},
}
</pre></div></div></div></div><div class="row" id="2021-vinci-etf-visualization"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2021-vinci-etf-visualization.webp" alt="Thumbnail of Interactive Simulation and Visualization of Long-Term, ETF-based Investment Strategies"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Interactive Simulation and Visualization of Long-Term, ETF-based Investment Strategies</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2021<p><small>Martin Büßemeyer, Daniel Limberger, Willy Scheibel, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2021-vinci-etf-visualization">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2021-vinci-etf-visualization">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3481549.3481568">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy-Scheibel/publication/354332166/inline/jsViewer/61486d4e519a1a381f702692">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2021-vinci-etf-visualization"><p>Personal, long-term investment products, especially ones for retirement savings, require thorough understanding to use them profitably. Even simple savings plans based on exchange-traded funds (ETFs) are subject to many variables and uncertainties to be considered for expected and planned-upon returns. We present aninteractive simulation of an ETF-based savings plan that combinesforecasts, risk awareness, taxes and costs, inflation, and dynamicinflows and outflows into a single visualization. The visualization consists of four parts; a form-fill interface for configuration, a savings and payout simulation, a cash flow chart, and a savings chart. Based on a specific use case, we discuss how private investors canbenefit from using our visualization after a short training period.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2021-vinci-etf-visualization"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="buessemeyer2021-etf-visualization.bib" href="/bibliography/buessemeyer2021-etf-visualization.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2021-vinci-etf-visualization" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2021-vinci-etf-visualization">@inproceedings{buessemeyer2021-etf-visualization,
  author = {B{\&quot;u}{\&quot;s}emeyer, Martin, and Limberger, Daniel and Scheibel, Willy and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Interactive Simulation and Visualization of Long-Term, ETF-based Investment Strategies},
  booktitle = {Proceedings of the 14th International Symposium on Visual Information Communication and Interaction},
  year = {2021},
  series = {VINCI~'21},
  publisher = {ACM},
  doi = {10.1145/3481549.3481568},
  isbn = {978-1-450386-47-0},
}
</pre></div></div></div></div><div class="row" id="2021-vinci-procedural-textures"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2021-vinci-procedural.webp" alt="Thumbnail of Visualization of Data Changes in 2.5D Treemaps using Procedural Textures and Animated Transitions"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Visualization of Data Changes in 2.5D Treemaps using Procedural Textures and Animated Transitions</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2021<p><small>Daniel Limberger, Willy Scheibel, Jan Dieken, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2021-vinci-procedural-textures">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2021-vinci-procedural-textures">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3481549.3481570">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy-Scheibel/publication/354331984/inline/jsViewer/61486d013c6cb310697e65f0">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2021-vinci-procedural-textures"><p>This work investigates the extent to which animated procedural texture patterns can be used to support the representation of changes in 2.5D treemaps. Changes in height, color, and area of individual nodes can easily be visualized using animated transitions. Especially for changes in the color attribute, plain animated transitions are not able to directly communicate the direction of change itself. We show how procedural texture patterns can be superimposed to the color mapping and support transitions. To this end, we discuss qualitative properties of each pattern, demonstrate their ability to communicate change direction both with and without animation, and conclude which of the patterns are more likely to increase effectiveness and correctness of the change mapping in 2.5D treemaps.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2021-vinci-procedural-textures"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2021-procedural.bib" href="/bibliography/limberger2021-procedural.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2021-vinci-procedural-textures" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2021-vinci-procedural-textures">@inproceedings{limberger2021-procedural,
  author = {Limberger, Daniel and Scheibel, Willy and Dieken, Jan and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Visualization of Data Changes in 2.5D Treemaps using Procedural Textures and Animated Transitions},
  booktitle = {Proceedings of the 14th International Symposium on Visual Information Communication and Interaction},
  year = {2021},
  series = {VINCI~'21},
  publisher = {ACM},
  pages = {21:1--5},
  doi = {10.1145/3481549.3481570},
  isbn = {978-1-450386-47-0},
}
</pre></div></div></div></div><div class="row" id="2021-vinci-software-galaxy"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2021-vinci-software-galaxy.webp" alt="Thumbnail of Software Galaxies: Displaying Coding Activities using a Galaxy Metaphor"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Software Galaxies: Displaying Coding Activities using a Galaxy Metaphor</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2021<p><small>Daniel Atzberger, Willy Scheibel, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2021-vinci-software-galaxy">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2021-vinci-software-galaxy">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3481549.3481573">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy-Scheibel/publication/354332172/inline/jsViewer/61486d33519a1a381f70268d">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2021-vinci-software-galaxy"><p>Software visualization uses metaphors to depict software and software development data that usually has no gestalt. The choice of a metaphor and visual depiction is researched broadly, but deriving a layout based on similarity is still challenging. We present a novel approach to 3D software visualization called Software Galaxy. Our layout is based on applying Latent Dirichlet Allocation on source code. We utilize a metaphor inspired from astronomy for depicting software metrics for single files and clusters. Our first experiments indicate that a 3D visualization capturing semantic relatedness can be beneficial for standard program comprehension tasks.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2021-vinci-software-galaxy"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2021-software-galaxy.bib" href="/bibliography/atzberger2021-software-galaxy.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2021-vinci-software-galaxy" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2021-vinci-software-galaxy">@inproceedings{atzberger2021-software-galaxy,
  author = {Atzberger, Daniel and Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Software Galaxies: Displaying Coding Activities using a Galaxy Metaphor},
  booktitle = {Proceedings of the 14th International Symposium on Visual Information Communication and Interaction},
  year = {2021},
  series = {VINCI~'21},
  publisher = {ACM},
  pages = {24:1--2},
  doi = {10.1145/3481549.3481573},
  isbn = {978-1-450386-47-0},
}
</pre></div></div></div></div><div class="row" id="2021-eurovis-roomcanvas"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2021-eurovis-roomcanvas.webp" alt="Thumbnail of RoomCanvas: A Visualization System for Spatiotemporal Temperature Data in Smart Homes"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>RoomCanvas: A Visualization System for Spatiotemporal Temperature Data in Smart Homes</h3><p></p>Proc. EG Int. Conf. on Visualization (EuroVis), 2021<p><small>Bastian König, Daniel Limberger, Jan Klimke, Benjamin Hagedorn, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2021-eurovis-roomcanvas">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2021-eurovis-roomcanvas">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.2312/evs.20211048">DOI</a>&ensp;|&ensp;<a href="https://diglib.eg.org/bitstream/handle/10.2312/evs20211048/013-017.pdf">Paper</a>&ensp;|&ensp;<a href="https://roomcanvas.dev/">Demo</a></p><div class="collapse abstract" data-bs-target id="abstract-2021-eurovis-roomcanvas"><p>Spatiotemporal measurements such as power consumption, temperature, humidity, movement, noise, brightness, etc., will become ubiquitously available in both old and modern homes to capture and analyze behavioral patterns. The data is fed into analytics platforms and tapped by services but is generally not readily available to consumers for exploration due in part to its inherent complexity and volume. We present an interactive visualization system that uses a simplified 3D representation of building interiors as a canvas for a unified sensor data display. The system’s underlying visualization supports spatial as well as temporal accumulation of data, e.g., temperature and humidity values. It introduces a volumetric data interpolation approach which takes 3D room boundaries such as walls, doors, and windows into account. We showcase an interactive, web-based prototype that allows for the exploration of historical as well as real-time data of multiple temperature and humidity sensors. Finally, we sketch an integrated pipeline from sensor data acquisition to visualization, discuss the creation of semantic geometry and subsequent preprocessing, and provide insights into our real-time rendering implementation.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2021-eurovis-roomcanvas"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="koenig2021-roomcanvas.bib" href="/bibliography/koenig2021-roomcanvas.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2021-eurovis-roomcanvas" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2021-eurovis-roomcanvas">@inproceedings{koenig2021-roomcanvas,
  author = {K{\&quot;o}nig, Bastian and Limberger, Daniel and Klimke, Jan and Hagedorn, Benjamin and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {RoomCanvas: A Visualization System for Spatiotemporal Temperature Data in Smart Homes},
  booktitle = {EuroVis 2021 - Short Papers},
  year = {2021},
  series = {EuroVis~'21},
  publisher = {EG},
  pages = {13--17},
  doi = {10.2312/evs.20211048},
  isbn = {978-3-038681-43-4},
}
</pre></div></div></div></div><div class="row" id="2021-ivapp-software-forest"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2021-ivapp-software-forest.webp" alt="Thumbnail of Software Forest: A Visualization of Semantic Similarities in Source Code using a Tree Metaphor"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Software Forest: A Visualization of Semantic Similarities in Source Code using a Tree Metaphor</h3><p></p>Proc. Int. Conf. on Information Visualization Theory and Applications (IVAPP), 2021<p><small>Daniel Atzberger, Tim Cech, Merlin de la Haye, Maximilian Söchting, Willy Scheibel, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2021-ivapp-software-forest">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2021-ivapp-software-forest">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0010267601120122">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy-Scheibel/publication/349382985/inline/jsViewer/6047926192851c077f2981ce">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2021-ivapp-software-forest"><p>Software visualization techniques provide effective means for program comprehension tasks as they allow developers to interactively explore large code bases. A frequently encountered task during software development is the detection of source code files of similar semantic. To assist this task we present Software Forest, a novel 2.5D software visualization that enables interactive exploration of semantic similarities within a software system, illustrated as a forest. The underlying layout results from the analysis of the vocabulary of the software documents using Latent Dirichlet Allocation and Multidimensional Scaling and therefore reflects the semantic similarity between source code files. By mapping properties of a software entity, e.g., size metrics or trend data, to visual variables encoded by various, figurative tree meshes, aspects of a software system can be displayed. This concept is complemented with implementation details as well as a discussion on applications.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2021-ivapp-software-forest"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="atzberger2021-software-forest.bib" href="/bibliography/atzberger2021-software-forest.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2021-ivapp-software-forest" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2021-ivapp-software-forest">@inproceedings{atzberger2021-software-forest,
  author = {Atzberger, Daniel and Cech, Tim and de la Haye, Merlin and S{\&quot;o}chting, Maximilian and Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Software Forest: A Visualization of Semantic Similarities in Source Code using a Tree Metaphor},
  booktitle = {Proceedings of the 16th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2021},
  series = {IVAPP~'21},
  publisher = {SciTePress},
  pages = {112--122},
  doi = {10.5220/0010267601120122},
  isbn = {978-9-897584-88-6},
}
</pre></div></div></div></div><div class="row" id="2020-vinci-survey-effectiveness"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2020-vinci-survey-effectiveness.webp" alt="Thumbnail of Survey on User Studies on the Effectiveness of Treemaps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Survey on User Studies on the Effectiveness of Treemaps</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2020<p><small>Carolin Fiedler, Willy Scheibel, Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2020-vinci-survey-effectiveness">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2020-vinci-survey-effectiveness">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3430036.3430054">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy_Scheibel/publication/346565359/inline/jsViewer/60083702a6fdccdcb8690e02">Paper</a>&ensp;|&ensp;<a href="https://varg-dev.github.io/treemap-studies">Website</a></p><div class="collapse abstract" data-bs-target id="abstract-2020-vinci-survey-effectiveness"><p>Treemaps are a commonly used tool for the visual display and communication of tree-structured, multi-variate data. In order to confidently know when and how treemaps can best be applied, the research community uses usability studies and controlled experiments to "understand the potential and limitations of our tools" (Plaisant, 2004). To support the communities' understanding and usage of treemaps, this survey provides a comprehensive review and detailed overview of 69 user studies related to treemaps. However, due to pitfalls and shortcomings in design, conduct, and reporting of the user studies, there is little that can be reliably derived or accepted as a generalized statement. Fundamental open questions include configuration, compatible tasks, use cases, and perceptional characteristics of treemaps. The reliability of findings and statements is discussed and common pitfalls of treemap user studies are identified.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2020-vinci-survey-effectiveness"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="fiedler2020-survey-effectiveness.bib" href="/bibliography/fiedler2020-survey-effectiveness.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2020-vinci-survey-effectiveness" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2020-vinci-survey-effectiveness">@inproceedings{fiedler2020-treemap-evaluation,
  author = {Fiedler, Carolin and Scheibel, Willy and Limberger, Daniel and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Survey on User Studies on the Effectiveness of Treemaps},
  booktitle = {Proceedings of the 13th International Symposium on Visual Information Communication and Interaction},
  year = {2020},
  series = {VINCI~'20},
  publisher = {ACM},
  pages = {2:1--10},
  doi = {10.1145/3430036.3430054},
  isbn = {978-1-450387-50-7},
}
</pre></div></div></div></div><div class="row" id="2020-vinci-survey-layouts"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2020-vinci-survey-layouts.webp" alt="Thumbnail of Survey of Treemap Layout Algorithms"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Survey of Treemap Layout Algorithms</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2020<p><small>Willy Scheibel, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2020-vinci-survey-layouts">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2020-vinci-survey-layouts">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3430036.3430041">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy_Scheibel/publication/346565429/inline/jsViewer/6008e5e9a6fdccdcb86bb8d0">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2020-vinci-survey-layouts"><p>This paper provides an overview of published treemap layout algorithms from 1991 to 2019 that were used for information visualization and computational geometry. First, a terminology is outlined for the precise communication of tree-structured data and layouting processes. Second, an overview and classification of layout algorithms is presented and application areas are discussed. Third, the use-case-specific adaption process is outlined and discussed. This overview targets practitioners and researchers by providing a starting point for own research, visualization design, and applications.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2020-vinci-survey-layouts"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="scheibel2020-survey-layouts.bib" href="/bibliography/scheibel2020-survey-layouts.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2020-vinci-survey-layouts" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2020-vinci-survey-layouts">@inproceedings{scheibel2020-survey-layouts,
  author = {Scheibel, Willy and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Survey of Treemap Layout Algorithms},
  booktitle = {Proceedings of the 13th International Symposium on Visual Information Communication and Interaction},
  year = {2020},
  series = {VINCI~'20},
  publisher = {ACM},
  pages = {1:1--9},
  doi = {10.1145/3430036.3430041},
  isbn = {978-1-450387-50-7},
}
</pre></div></div></div></div><div class="row" id="2020-vinci-uncertainty"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2020-vinci-uncertainty.webp" alt="Thumbnail of Depicting Uncertainty in 2.5D Treemaps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Depicting Uncertainty in 2.5D Treemaps</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2020<p><small>Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2020-vinci-uncertainty">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2020-vinci-uncertainty">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3430036.3432753">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Matthias-Trapp-2/publication/347313642/inline/jsViewer/60acf193a6fdcc647ed752cc">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2020-vinci-uncertainty"><p>A truthful and unbiased display of data using information visualization requires detecting and communicating uncertainty. Uncertainty is often inherent in data or is introduced by data processing and visualization (e.g., visual display of accumulated data) but frequently not accounted for. This paper discusses the suitability of advanced visual variables such as sketchiness, noise, nesting-level contouring, and color weaving for communicating uncertainty.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2020-vinci-uncertainty"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2020-uncertainty.bib" href="/bibliography/limberger2020-uncertainty.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2020-vinci-uncertainty" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2020-vinci-uncertainty">@inproceedings{limberger2020-uncertainty,
  author = {Limberger, Daniel and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Depicting Uncertainty in 2.5D Treemaps},
  booktitle = {Proceedings of the 13th International Symposium on Visual Information Communication and Interaction},
  year = {2020},
  series = {VINCI~'20},
  publisher = {ACM},
  articleno = {28:1--2},
  doi = {10.1145/3430036.3432753},
  isbn = {978-1-450387-50-7},
}
</pre></div></div></div></div><div class="row" id="2020-web3d-pbr-lighting"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2020-web3d-pbr-lighting.webp" alt="Thumbnail of Physically-based Environment and Area Lighting using Progressive Rendering in WebGL"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Physically-based Environment and Area Lighting using Progressive Rendering in WebGL</h3><p></p>Proc. ACM Int. Conf. on Web3D Technology (Web3D), 2020<p><small>Philipp Otto, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2020-web3d-pbr-lighting">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2020-web3d-pbr-lighting">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3424616.3424697">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel-Limberger/publication/347578774/inline/jsViewer/60ae14d5a6fdcc647edc3760">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2020-web3d-pbr-lighting"><p>This paper presents a progressive rendering approach that enables rendering of static 3D scenes, lit by physically-based environment and area lights. Multi-frame sampling strategies are used to approximate elaborate lighting that is refined while showing intermediate results to the user. The presented approach enables interactive yet high-quality rendering in the web and runs on a wide range of devices including low-performance hardware such as mobile devices. An open-source implementation of the described techniques using TypeScript and WebGL 2.0 is presented and provided. For evaluation, we compare our rendering results to both a path tracer and a physically-based rasterizer. Our findings show that the approach approximates the lighting and shadowing of the path-traced reference well while being faster than the compared rasterizer.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2020-web3d-pbr-lighting"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="otto2020-pbr-lighting.bib" href="/bibliography/otto2020-pbr-lighting.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2020-web3d-pbr-lighting" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2020-web3d-pbr-lighting">@inproceedings{otto2020-pbr-lighting,
  author = {Otto, Philipp and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Physically-based Environment and Area Lighting using Progressive Rendering in WebGL},
  booktitle = {Proceedings of the 25th International Conference on 3D Web Technology},
  year = {2020},
  series = {Web3D~'20},
  publisher = {ACM},
  pages = {15:1--9},
  doi = {10.1145/3424616.3424697},
  isbn = {978-1-450381-69-7},
}
</pre></div></div></div></div><div class="row" id="2020-web3d-scatter-plot"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2020-web3d-scatter-plot.webp" alt="Thumbnail of A Framework for Interactive Exploration of Clusters in Massive Data using 3D Scatter Plots and WebGL"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>A Framework for Interactive Exploration of Clusters in Massive Data using 3D Scatter Plots and WebGL</h3><p></p>Proc. ACM Int. Conf. on Web3D Technology (Web3D), 2020<p><small>Lukas Wagner, Willy Scheibel, Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2020-web3d-scatter-plot">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2020-web3d-scatter-plot">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3424616.3424730">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Lukas-Wagner-17/publication/345770726/inline/jsViewer/5fbe75cb299bf104cf770132">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2020-web3d-scatter-plot"><p>This paper presents a rendering framework for the visualization of massive point datasets in the web. It includes highly interactive point rendering, cluster visualization, basic interaction methods, and importance-based labeling, while being available for both mobile and desktop browsers. The rendering style is customizable, as shown in figure 1. Our evaluation indicates that the framework facilitates interactive visualization of tens of millions of raw data points even without dynamic filtering or aggregation.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2020-web3d-scatter-plot"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="wagner2020-scatter-plot.bib" href="/bibliography/wagner2020-scatter-plot.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2020-web3d-scatter-plot" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2020-web3d-scatter-plot">@inproceedings{wagner2020-scatter-plot,
  author = {Wagner, Lukas and Limberger, Daniel and Scheibel, Willy and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {A Framework for Interactive Exploration of Clusters in Massive Data using 3D Scatter Plots and WebGL},
  booktitle = {Proceedings of the 25th International Conference on 3D Web Technology},
  year = {2020},
  series = {Web3D~'20},
  publisher = {ACM},
  pages = {31:1--2},
  doi = {10.1145/3424616.3424730},
  isbn = {978-1-450381-69-7},
}
</pre></div></div></div></div><div class="row" id="2020-treemap-taxonomy"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2020-ivapp-treemap-taxonomy.webp" alt="Thumbnail of A Taxonomy of Treemap Visualization Techniques"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>A Taxonomy of Treemap Visualization Techniques</h3><p></p>Proc. Int. Conf. on Information Visualization Theory and Applications (IVAPP), 2020<p><small>Willy Scheibel, Matthias Trapp, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2020-treemap-taxonomy">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2020-treemap-taxonomy">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0009153902730280">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy_Scheibel/publication/338402878/inline/jsViewer/5e5cd038a6fdccbeba12bf83">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy_Scheibel/publication/339617725/inline/jsViewer/5e5cd13ba6fdccbeba12bfea">Slides</a></p><div class="collapse abstract" data-bs-target id="abstract-2020-treemap-taxonomy"><p>A treemap is a visualization that has been specifically designed to facilitate the exploration of tree-structured data and, more general, hierarchically structured data. The family of visualization techniques that use a visual metaphor for parent-child relationships based "on the property of containment" (Johnson, 1993) is commonly referred to as treemaps. However, as the number of variations of treemaps grows, it becomes increasingly important to distinguish clearly between techniques and their specific characteristics. This paper proposes to discern between Space-filling Treemap, Containment Treemap, Implicit Edge Representation Tree, and Mapped Tree for classification of hierarchy visualization techniques and highlights their respective properties. This taxonomy is created as a hyponymy, i.e., its classes have an is-a relationship to one another. With this proposal, we intend to stimulate a discussion on a more unambiguous classification of treemaps and, furthermore, broaden what is understood by the concept of treemap itself.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2020-treemap-taxonomy"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="scheibel2020-treemap-taxonomy.bib" href="/bibliography/scheibel2020-treemap-taxonomy.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2020-treemap-taxonomy" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2020-treemap-taxonomy">@inproceedings{scheibel2020-taxonomy,
  author = {Scheibel, Willy and Trapp, Matthias and Limberger, Daniel and J{\&quot;u}rgen D{\&quot;o}llner},
  title = {A Taxonomy of Treemap Visualization Techniques},
  booktitle = {Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2020},
  series = {VISIGRAPP~'20},
  publisher = {SciTePress},
  pages = {273--280},
  doi = {10.5220/0009153902730280},
  isbn = {978-9-897584-02-2},
}

</pre></div></div></div></div><div class="row" id="2019-hiviser-extended"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2019-ivapp-hiviser-extended.webp" alt="Thumbnail of Visualization of Tree-structured Data using Web Service Composition"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Visualization of Tree-structured Data using Web Service Composition</h3><p></p>VISIGRAPP 2019: Computer Vision, Imaging and Computer Graphics Theory and Applications, 2020<p><small>Willy Scheibel, Judith Hartmann, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2019-hiviser-extended">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2019-hiviser-extended">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1007/978-3-030-41590-7_10">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy_Scheibel/publication/339362147/inline/jsViewer/5e5ccf0c4585152ce8ff8d73">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2019-hiviser-extended"><p>This article reiterates on the recently presented hierarchy visualization service HiViSer and its API. It illustrates its decomposition into modular services for data processing and visualization of tree-structured data. The decomposition is aligned to the common structure of visualization pipelines and, in this way, facilitates attribution of the services' capabilities. Suitable base resource types are proposed and their structure and relations as well as a subtyping concept for specifics in hierarchy visualization implementations are detailed. Moreover, state-of-the-art quality standards and techniques for self-documentation and discovery of components are incorporated. As a result, a blueprint for Web service design, architecture, modularization, and composition is presented, targeting fundamental visualization tasks of tree-structured data, i.e., gathering, processing, rendering, and provisioning. Finally, the applicability of the service components and the API is evaluated in the context of exemplary applications.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2019-hiviser-extended"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="scheibel2019-hiviser-extended.bib" href="/bibliography/scheibel2019-hiviser-extended.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2019-hiviser-extended" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2019-hiviser-extended">@inproceedings{scheibel2019-hiviser-extended,
  author = {Scheibel, Willy and Hartmann, Judith and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Visualization of Tree-structured Data using Web Service Composition},
  booktitle = {Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2019},
  publisher = {Springer},
  pages = {227--252},
  doi = {10.1007/978-3-030-41590-7_10},
  isbn = {978-3-030415-90-7},
}
</pre></div></div></div></div><div class="row" id="2019-vinci-advanced"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2019-vinci-advanced.webp" alt="Thumbnail of Advanced Visual Metaphors and Techniques for Software Maps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Advanced Visual Metaphors and Techniques for Software Maps</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2019<p><small>Daniel Limberger, Willy Scheibel, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2019-vinci-advanced">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2019-vinci-advanced">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3356422.3356444">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/335062804/inline/jsViewer/5d883828a6fdcc8fd6106c95">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2019-vinci-advanced"><p>Software maps provide a general-purpose interactive user interface and information display for software analytics tools. This paper systematically introduces and classifies software maps as a treemap-based technique for software cartography. It provides an overview of advanced visual metaphors and techniques, each suitable for interactive visual analytics tasks, that can be used to enhance the expressiveness of software maps. Thereto, the metaphors and techniques are briefly described, located within a visualization pipeline model, and considered within the software map design space. Consequent applications and use cases w.r.t. different types of software system data and software engineering data are discussed, arguing for a versatile use of software maps in visual software analytics.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2019-vinci-advanced"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2019-advanced.bib" href="/bibliography/limberger2019-advanced.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2019-vinci-advanced" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2019-vinci-advanced">@inproceedings{limberger2019-advanced,
  author = {Limberger, Daniel and Scheibel, Willy and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Advanced Visual Metaphors and Techniques for Software Maps},
  booktitle = {Proceedings of the 12th International Symposium on Visual Information Communication and Interaction},
  year = {2019},
  series = {VINCI~'19},
  publisher = {ACM},
  pages = {11:1--8},
  doi = {10.1145/3356422.3356444},
  isbn = {978-1-450376-26-6},
}
</pre></div></div></div></div><div class="row" id="2019-ivapp-insitu"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2019-ivapp-insitu.webp" alt="Thumbnail of In-Situ Comparison for 2.5D Treemaps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>In-Situ Comparison for 2.5D Treemaps</h3><p></p>Proc. Int. Conf. on Information Visualization Theory and Applications (IVAPP), 2019<p><small>Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2019-ivapp-insitu">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2019-ivapp-insitu">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0007576203140321">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/330195762/inline/jsViewer/5c77b7d592851c695046e613">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/331399508/inline/jsViewer/5c77b9a3a6fdcc4715a1c58c">Poster</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/331400019_In-Situ_Comparison_for_25D_Treemaps_-_Templates/data/5c77c029458515831f75e389/2019-Limberger-In-Situ-Comparison-for-25D-Treemaps-Templates.pdf">Template Card</a></p><div class="collapse abstract" data-bs-target id="abstract-2019-ivapp-insitu"><p>2.5D treemaps can be used to visualize tree-structured data using the height dimension for additional information display. For tree-structured and time-variant data though, changes or variants in the data are difficult to visualize. This paper presents an in-situ approach to depict differences between two versions (original and comparative state) of a data set, e.g., metrics of different revisions of a software system, in a single 2.5D treemap. Multiple geometry variants for the in-situ representation of individual nodes, especially concerning height, area, and color, are presented and discussed. Finally, a preliminary study for the simultaneous change of attributes in height and area is described, hinting that arrow pattern help to clarify reading direction.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2019-ivapp-insitu"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2019-insitu.bib" href="/bibliography/limberger2019-insitu.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2019-ivapp-insitu" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2019-ivapp-insitu">@inproceedings{limberger2019-insitu,
  author = {Limberger, Daniel and Trapp, Matthias and D{\&quot;ö}llner, J{\&quot;ü}rgen},
  title = {In-Situ Comparison for 2.5D Treemaps},
  booktitle = {Proceedings of the 14th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2019},
  series = {IVAPP~'19},
  publisher = {SciTePress},
  pages = {314--321},
  doi = {10.5220/0007576203140321},
  isbn = {978-9-897583-54-4},
}
</pre></div></div></div></div><div class="row" id="2018-vinci-reference"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2018-vinci-reference.webp" alt="Thumbnail of Interactive, Height-based Filtering in 2.5D Treemaps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Interactive, Height-based Filtering in 2.5D Treemaps</h3><p></p>Proc. ACM Int. Symp. on Visual Information Communication and Interaction (VINCI), 2018<p><small>Daniel Limberger, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2018-vinci-reference">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2018-vinci-reference">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3231622.3231638">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/326728307/inline/jsViewer/5b72cb95a6fdcc87df79e161">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Matthias_Trapp/publication/330106559/inline/jsViewer/5c2df2f4299bf12be3aaf161">Slides</a></p><div class="collapse abstract" data-bs-target id="abstract-2018-vinci-reference"><p>The 2.5D treemap facilitates interactive exploration of multivariate data. It includes height as a visual variable for additional information display and enables exploration of correlations within mapped attributes. In this paper techniques for the visual display of a height reference for interactive modification from within the visualization are introduced. Results of a preliminary user study are presented and potential benefits for improved performance, i.e., precision and speed, of identification, comparison, filtering, and selection tasks are discussed.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2018-vinci-reference"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2018-reference.bib" href="/bibliography/limberger2018-reference.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2018-vinci-reference" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2018-vinci-reference">@inproceedings{limberger2018-reference,
  author = {Limberger, Daniel and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Interactive, Height-Based Filtering in 2.5D Treemaps},
  booktitle = {Proceedings of the 11th International Symposium on Visual Information Communication and Interaction},
  year = {2018},
  series = {VINCI~'18},
  publisher = {ACM},
  pages = {49--55},
  doi = {10.1145/3231622.3231638},
  isbn = {978-1-450365-01-7},
}
</pre></div></div></div></div><div class="row" id="2018-gpu360-multi-frame-sampling"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2018-gpu360-multi-frame-sampling.webp" alt="Thumbnail of Progressive Rendering using Multi-frame Sampling | Reprint of the GPU Pro 7 Article"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Progressive Rendering using Multi-frame Sampling | Reprint of the GPU Pro 7 Article</h3><p></p>GPU Pro 360 Guide to Rendering, 2018<p><small>Daniel Limberger, Karsten Tausche, Johannes Linke, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2018-gpu360-multi-frame-sampling">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2018-gpu360-multi-frame-sampling">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1201/9781351261524">DOI</a></p><div class="collapse abstract" data-bs-target id="abstract-2018-gpu360-multi-frame-sampling"><p>This chapter presents an approach that distributes sampling over multiple, consecutive frames, and, thereby, enables sampling-based, real-time rendering techniques to be implemented for most graphics hardware and systems in a less complex, straightforward way. This systematic, extensible schema allows developers to effectively handle the increasing implementation complexity of advanced, sophisticated, real-time rendering techniques, while improving responsiveness and reducing required hardware resources.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2018-gpu360-multi-frame-sampling"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2018-multi-frame-pro.bib" href="/bibliography/limberger2018-multi-frame-pro.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2018-gpu360-multi-frame-sampling" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2018-gpu360-multi-frame-sampling">@article{limberger2018-multi-frame-pro,
  title = {Progressive Rendering using Multi-frame Sampling},
  author = {Limberger, Daniel and Tausche, Karsten and Linke, Johannes and D{\&quot;o}llner, J{\&quot;u}rgen},
  journal = {GPU Pro 360 Guide to Rendering},
  year = {2018},
  publisher = {A. K. Peters, Ltd.},
  pages = {537--553},
  doi = {10.1201/9781351261524},
  isbn = {978-1-351261-52-4},
  note = {Reprint of the GPU Pro 7 Article, 2016},
}
</pre></div></div></div></div><div class="row" id="2018-patent-lod-treemaps"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2018-patent-lod-treemaps.webp" alt="Thumbnail of Interactive, Adaptive Level-of-Detail in 2.5D Treemaps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Interactive, Adaptive Level-of-Detail in 2.5D Treemaps</h3><p></p>United States Patent and Trademark Office, 2018<p><small>Daniel Limberger</small></p><p><a data-bs-toggle="collapse" href="#abstract-2018-patent-lod-treemaps">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2018-patent-lod-treemaps">BibTeX</a>&ensp;|&ensp;<a href="https://patents.google.com/patent/US9953443B2/en">Patent</a>&ensp;|&ensp;<a href="https://globaldossier.uspto.gov/#/result/patent/US/9953443/1">USPTO</a></p><div class="collapse abstract" data-bs-target id="abstract-2018-patent-lod-treemaps"><p>An aggregation approach allows for a dynamic, interactive, adaptive level-of-detail for 2D, 2.5D, and 3D treemaps for visualization of complex information. For example, the 2.5D treemap visualization concept is extended by providing adaptive identification of aggregates by means of an interactive node scoring approach based on contextual relevance and various other task, interaction, visibility, and/or performance specific criteria. For the resulting mapping and rendering, a per-frame aggregation of blocks and accumulation of those attributes mapped to visual variables (context) is described. Since every embodiment is also targeted for dynamic, interactive visual display of 2.5D treemaps, the rendering is designed to be capable for execution in real-time. Visual preservation of important information is conveyed by hierarchy elements and their mapped attributes (nodes-of-interest) as well as compliance to known aggregation guidelines including visualization of aggregated color and height information, visualization of aggregates that are discernible from non-aggregates, and visualization of outliers within aggregates. Applications include visualization of software maps, business intelligence data, file hierarchies for storage devices, and the like.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2018-patent-lod-treemaps"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2018-lod-patent.bib" href="/bibliography/limberger2018-lod-patent.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2018-patent-lod-treemaps" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2018-patent-lod-treemaps">@patent{limberger2018-lod-patent,
  title = {Interactive, Adaptive Level-of-Detail in 2.5 D Treemaps},
  author = {Limberger, Daniel},
  year = {2018},
  date = {2018-04-24},
  number = {9953443},
  holder = {Seerene GmbH},
  type = {patentus},
}
</pre></div></div></div></div><div class="row" id="2018-iv-open-ll"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2018-iv-open-ll.webp" alt="Thumbnail of OpenLL: an API for Dynamic 2D and 3D Labeling"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>OpenLL: an API for Dynamic 2D and 3D Labeling</h3><p></p>Proc. IEEE Int. Conf. Information Visualisation (iV), 2018<p><small>Daniel Limberger, Anne Gropler, Stefan Buschmann, Jürgen Döllner, and Benjamin Wasty</small></p><p><a data-bs-toggle="collapse" href="#abstract-2018-iv-open-ll">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2018-iv-open-ll">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1109/iV.2018.00039">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/327017928/inline/jsViewer/5b72c86845851546c902c9f1">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/331400327/inline/jsViewer/5c77cc29458515831f75e5e4">Slides</a></p><div class="collapse abstract" data-bs-target id="abstract-2018-iv-open-ll"><p>Today's rendering APIs lack robust functionality and capabilities for dynamic, real-time text rendering and labeling, which represent key requirements for 3D application design in many fields. As a consequence, most rendering systems are barely or not at all equipped with respective capabilities. This paper drafts the unified text rendering and labeling API OpenLL intended to complement common rendering APIs, frameworks, and transmission formats. For it, various uses of static and dynamic placement of labels are showcased and a text interaction technique is presented. Furthermore, API design constraints with respect to state-of-the-art text rendering techniques are discussed. This contribution is intended to initiate a community-driven specification of a free and open label library.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2018-iv-open-ll"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2018-openll.bib" href="/bibliography/limberger2018-openll.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2018-iv-open-ll" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2018-iv-open-ll">@inproceedings{limberger2018-openll,
  author = {Limberger, Daniel and Gropler, Anne and Buschmann, Stefan and Wasty, Benjamin and D{\&quot;o}llner, J{\&quot;u}rgen},
  booktitle = {22nd International Conference Information Visualisation},
  title = {OpenLL: An API for Dynamic 2D and 3D Labeling},
  year = {2018},
  series = {IV~'18},
  publisher = {IEEE},
  pages = {175--181},
  doi = {10.1109/iV.2018.00039},
  isbn = {978-1-538672-02-0},
}
</pre></div></div></div></div><div class="row" id="2017-iv-mixed-projection"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2017-iv-mixed-projection.webp" alt="Thumbnail of Mixed-Projection Treemaps: A Novel Approach Mixing 2D and 2.5D Treemaps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Mixed-Projection Treemaps: A Novel Approach Mixing 2D and 2.5D Treemaps</h3><p></p>Proc. IEEE Int. Conf. Information Visualisation (iV), 2017<p><small>Daniel Limberger, Willy Scheibel, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2017-iv-mixed-projection">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2017-iv-mixed-projection">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1109/iV.2017.67">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/316999964/inline/jsViewer/5ab28be2aca272171001b92a">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/330106367/inline/jsViewer/5c77be80458515831f75e32b">Slides</a></p><div class="collapse abstract" data-bs-target id="abstract-2017-iv-mixed-projection"><p>This paper presents a novel technique for combining 2D and 2.5D treemaps using multi-perspective views to leverage the advantages of both treemap types. It enables a new form of overview+detail visualization for tree-structured data and contributes new concepts for real-time rendering of and interaction with treemaps. The technique operates by tilting the graphical elements representing inner nodes using affine transformations and animated state transitions. We explain how to mix orthogonal and perspective projections within a single treemap. Finally, we show application examples that benefit from the reduced interaction overhead.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2017-iv-mixed-projection"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2017-mixed.bib" href="/bibliography/limberger2017-mixed.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2017-iv-mixed-projection" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2017-iv-mixed-projection">@inproceedings{limberger2017-mixed,
  author = {Limberger, Daniel and Scheibel, Willy and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Mixed-Projection Treemaps: A Novel Approach Mixing 2D and 2.5D Treemaps},
  booktitle = {21st International Conference Information Visualisation},
  year = {2017},
  series = {IV~'17},
  publisher = {IEEE},
  pages = {164--169},
  doi = {10.1109/iV.2017.67},
  isbn = {978-1-538608-31-9},
}
</pre></div></div></div></div><div class="row" id="2017-web3d-progressive"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2017-web3d-progressive.webp" alt="Thumbnail of Progressive High-Quality Rendering for Interactive Information Cartography using WebGL"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Progressive High-Quality Rendering for Interactive Information Cartography using WebGL</h3><p></p>Proc. ACM Int. Conf. on 3D Web Technology (Web3D), 2017,&nbsp;<a href="https://twitter.com/Web3DConsortium/status/872336310027079683/photo/1">Best Paper</a><p><small>Daniel Limberger, Marcel Pursche, Jan Klimke, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2017-web3d-progressive">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2017-web3d-progressive">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/3055624.3075951">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/316999882/inline/jsViewer/5b72cc00a6fdcc87df79e788">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2017-web3d-progressive"><p>Information cartography services provided via web-based clients using real-time rendering do not always necessitate a continuous stream of updates in the visual display. This paper shows how progressive rendering by means of multi-frame sampling and frame accumulation can introduce high-quality visual effects using robust and straightforward implementations. For it, (1) a suitable rendering loop is described, (2) WebGL limitations are discussed, and (3) an adaption of THREE.js featuring progressive anti-aliasing, screen-space ambient occlusion, and depth of field is detailed. Furthermore, sampling strategies are discussed and rendering performance is evaluated, emphasizing the low per-frame costs of this approach.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2017-web3d-progressive"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2017-progressive.bib" href="/bibliography/limberger2017-progressive.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2017-web3d-progressive" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2017-web3d-progressive">@inproceedings{limberger2017-progressive,
  author = {Limberger, Daniel and Pursche, Marcel and Klimke, Jan and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Progressive High-quality Rendering for Interactive Information Cartography using WebGL},
  booktitle = {Proceedings of the 22nd International Conference on 3D Web Technology},
  year = {2017},
  series = {Web3D~'17},
  publisher = {ACM},
  pages = {8:1--4},
  doi = {10.1145/3055624.3075951},
  isbn = {978-1-450349-55-0},
}
</pre></div></div></div></div><div class="row" id="2017-ivapp-aggregation-swmaps"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2017-ivapp-aggregation-swmaps.webp" alt="Thumbnail of Reducing Visual Complexity in Software Maps using Importance-based Aggregation of Nodes"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Reducing Visual Complexity in Software Maps using Importance-based Aggregation of Nodes</h3><p></p>Proc. Int. Conf. on Information Visualization Theory and Applications (IVAPP), 2017<p><small>Daniel Limberger, Willy Scheibel, Sebastian Hahn, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2017-ivapp-aggregation-swmaps">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2017-ivapp-aggregation-swmaps">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.5220/0006267501760185">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/313377340/inline/jsViewer/589dbd3845851598bab4014b">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/331407406/inline/jsViewer/5c77deb8299bf1268d2c7c7b">Slides</a></p><div class="collapse abstract" data-bs-target id="abstract-2017-ivapp-aggregation-swmaps"><p>Depicting massive software system data using treemaps can result in visual clutter and increased cognitive load. This paper introduces an adaptive level-of-detail (LoD) technique that uses scoring for interactive aggregation on a per-node basis. The scoring approximates importance by degree-of-interest measures as well as screen and user-interaction scores. The technique adheres to established aggregation guidelines and was evaluated by means of two user studies. The first investigates task completion time in visual search. The second evaluates the readability of the presented nesting level contouring for aggregates. With the adaptive LoD technique software maps allow for multi-resolution depictions of software system information while facilitating annotation and efficient identification of important nodes.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2017-ivapp-aggregation-swmaps"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2017-aggregation.bib" href="/bibliography/limberger2017-aggregation.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2017-ivapp-aggregation-swmaps" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2017-ivapp-aggregation-swmaps">@inproceedings{limberger2017-aggregation,
  author = {Limberger, Daniel and Scheibel, Willy and Hahn, Sebastian and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Reducing Visual Complexity in Software Maps using Importance-based Aggregation of Nodes},
  booktitle = {Proceedings of the 12th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
  year = {2017},
  series = {IVAPP~'17},
  publisher = {SciTePress},
  pages = {176--185},
  doi = {10.5220/0006267501760185},
  isbn = {978-9-897582-28-8},
}
</pre></div></div></div></div><div class="row" id="2016-siggrapg-multi-frame-sampling"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2016-siggraph-multi-frame-sampling.webp" alt="Thumbnail of Real-time Rendering of High-quality Effects using Multi-frame Sampling"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Real-time Rendering of High-quality Effects using Multi-frame Sampling</h3><p></p>ACM SIGGRAPH Posters, 2016<p><small>Daniel Limberger and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2016-siggrapg-multi-frame-sampling">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2016-siggrapg-multi-frame-sampling">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/2945078.2945157">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/305082223/inline/jsViewer/5c7feab2458515831f8afeb8">Poster</a>&ensp;|&ensp;<a href="https://github.com/cgcostume/multiframesampling">Source Code</a>&ensp;|&ensp;<a href="http://cgcostume.github.io/mfsv/">Demo</a></p><div class="collapse abstract" data-bs-target id="abstract-2016-siggrapg-multi-frame-sampling"><p>In a rendering environment of comparatively sparse interaction, e.g., digital production tools, image synthesis and its quality do not have to be constrained to single frames. This work analyzes strategies for highly economically rendering of state-of-the-art rendering effects using progressive multi-frame sampling in real-time. By distributing and accumulating samples of sampling-based rendering techniques (e.g., anti-aliasing, orderindependent transparency, depth-of-field and shadowing, ambient occlusion, screen-space reflections) over multiple frames, images of very high quality can be synthesized with unequaled resource-efficiency.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2016-siggrapg-multi-frame-sampling"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2016-multi-frame-sampling.bib" href="/bibliography/limberger2016-multi-frame-sampling.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2016-siggrapg-multi-frame-sampling" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2016-siggrapg-multi-frame-sampling">@inproceedings{limberger2016-multi-frame-sampling,
  author = {Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Real-time Rendering of High-quality Effects using Multi-frame Sampling},
  booktitle = {ACM SIGGRAPH 2016 Posters},
  year = {2016},
  series = {SIGGRAPH~'16},
  pages = {79:1--1},
  publisher = {ACM},
  doi = {10.1145/2945078.2945157},
  isbn = {978-1-4503-4371-8},
}
</pre></div></div></div></div><div class="row" id="2016-web3d-declarative-treemaps"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2016-web3d-declarative-treemaps.webp" alt="Thumbnail of Dynamic 2.5D Treemaps using Declarative 3D on the Web"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Dynamic 2.5D Treemaps using Declarative 3D on the Web</h3><p></p>Proc. ACM Int. Conf. on Web3D Technology (Web3D), 2016<p><small>Daniel Limberger, Willy Scheibel, Stefan Lemme, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2016-web3d-declarative-treemaps">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2016-web3d-declarative-treemaps">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/2945292.2945313">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Willy_Scheibel/publication/305420771/inline/jsViewer/5b2cb47b4585150d23c1f3ea">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/331407662/inline/jsViewer/5c77e4fa299bf1268d2c7e74">Slides</a>&ensp;|&ensp;<a href="https://github.com/cgcostume/web3d-treemaps">Source Code</a>&ensp;|&ensp;<a href="http://cgcostume.github.io/web3d-treemaps/">Demo</a></p><div class="collapse abstract" data-bs-target id="abstract-2016-web3d-declarative-treemaps"><p>The 2.5D treemap represents a general purpose visualization technique to map multi-variate hierarchical data in a scalable, interactive, and consistent way used in a number of application fields. In this paper, we explore the capabilities of Declarative 3D for the web-based implementation of 2.5D treemap clients. Particularly, we investigate how X3DOM and XML3D can be used to implement clients with equivalent features that interactively display 2.5D treemaps with dynamic mapping of attributes. We also show a first step towards a glTF-based implementation. These approaches are benchmarked focusing on their interaction capabilities with respect to rendering and speed of dynamic data mapping. We discuss the results for our representative example of a complex 3D interactive visualization technique and summerize recommendations for improvements towards operational web clients.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2016-web3d-declarative-treemaps"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2016-declarative-treemaps.bib" href="/bibliography/limberger2016-declarative-treemaps.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2016-web3d-declarative-treemaps" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2016-web3d-declarative-treemaps">@inproceedings{limberger2016-declarative-treemaps,
  author = {Limberger, Daniel and Scheibel, Willy and Lemme, Stefan and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Dynamic 2.5D Treemaps using Declarative 3D on the Web},
  booktitle = {Proceedings of the 21st International Conference on Web3D Technology},
  year = {2016},
  series = {Web3D~'16},
  publisher = {ACM},
  pages = {33--36},
  doi = {10.1145/2945292.2945313},
  isbn = {978-1-450344-28-9},
}
</pre></div></div></div></div><div class="row" id="2016-iv-sketchiness-treemaps"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2016-iv-sketchiness-in-treemaps.webp" alt="Thumbnail of Evaluation of Sketchiness as a Visual Variable for 2.5D Treemaps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Evaluation of Sketchiness as a Visual Variable for 2.5D Treemaps</h3><p></p>Proc. IEEE Int. Conf. Information Visualisation (iV), 2016<p><small>Daniel Limberger, Carolin Fiedler, Sebastian Hahn, Matthias Trapp, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2016-iv-sketchiness-treemaps">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2016-iv-sketchiness-treemaps">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1109/IV.2016.61">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Matthias_Trapp/publication/301682636/inline/jsViewer/5addc0c7458515c60f5f7065">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2016-iv-sketchiness-treemaps"><p>Treemaps serve as generic, effective tools to display, explore, and analyze multi-variate tree data in a scalable, interactive, and consistent way In this paper, we discuss and evaluate sketchiness as visual variable of 2.5D treemaps. Sketchy rendering techniques allow us to map data, e.g., about uncertainty, imprecision, or vagueness, independently from mappings to other visual variables such as size, color, and height. To this end, we present a design space for sketchy rendering for 2.5D treemaps and corresponding implementation of a real-time sketchy rendering technique. The results of three user studies carried out indicate that sketchiness is a promising candidate for an independent visual variable for 2.5D treemaps, in particular to map ordinal data with a small range such as data that qualifies map items, it shows no strong interference with other visual variables such as color and height due to the regular gestalt of blocks and, hence, allows us to extend the expressiveness of 2.5D treemaps.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2016-iv-sketchiness-treemaps"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2016-sketchiness-treemaps.bib" href="/bibliography/limberger2016-sketchiness-treemaps.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2016-iv-sketchiness-treemaps" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2016-iv-sketchiness-treemaps">@inproceedings{limberger2016-sketchiness-treemaps,
  author = {Limberger, Daniel and Fiedler, Carolin and Hahn, Sebastian and Trapp, Matthias and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Evaluation of Sketchiness as a Visual Variable for 2.5D Treemaps},
  booktitle = {20th International Conference Information Visualisation},
  year = {2016},
  series = {IV~'16},
  publisher = {IEEE},
  pages = {183--189},
  doi = {10.1109/IV.2016.61},
  isbn = {978-1-467389-42-6},
}
</pre></div></div></div></div><div class="row" id="2016-gpupro-multi-frame-sampling"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2016-gpupro-multi-frame-sampling.webp" alt="Thumbnail of Progressive Rendering using Multi-frame Sampling"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Progressive Rendering using Multi-frame Sampling</h3><p></p>GPU Pro 7: Advanced Rendering Techniques, 2016<p><small>Daniel Limberger, Karsten Tausche, Johannes Linke, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2016-gpupro-multi-frame-sampling">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2016-gpupro-multi-frame-sampling">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1201/b21261">DOI</a></p><div class="collapse abstract" data-bs-target id="abstract-2016-gpupro-multi-frame-sampling"><p>This chapter presents an approach that distributes sampling over multiple, consecutive frames, and, thereby, enables sampling-based, real-time rendering techniques to be implemented for most graphics hardware and systems in a less complex, straightforward way. This systematic, extensible schema allows developers to effectively handle the increasing implementation complexity of advanced, sophisticated, real-time rendering techniques, while improving responsiveness and reducing required hardware resources.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2016-gpupro-multi-frame-sampling"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2016-multi-frame-sampling-pro.bib" href="/bibliography/limberger2016-multi-frame-sampling-pro.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2016-gpupro-multi-frame-sampling" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2016-gpupro-multi-frame-sampling">@article{limberger2016-multi-frame-sampling-pro,
  author = {Limberger, Daniel and Tausche, Karsten and Linke, Johannes and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Progressive Rendering using Multi-frame Sampling},
  journal = {GPU Pro 7: Advanced Rendering Techniques},
  year = {2016},
  publisher = {CRC Press},
  pages = {155--173},
  doi = {10.1201/b21261},
  isbn = {978-0-429160-03-5},
}
</pre></div></div></div></div><div class="row" id="2016-cgf-oilpaint-stylization"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><a class="thumbnail flickr" href="https://www.flickr.com/photos/131006004@N06/sets/72157652814171753/" data-photoset-id="72157652814171753"><span class="badge bg-primary position-absolute top-0 start-0">Flickr</span></a><img class="img-fluid rounded" width="768" height="768" src="/images/2016-cgf-interactive-oil-paint-filtering.webp" alt="Thumbnail of Image Stylization by Interactive Oil Paint Filtering"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Image Stylization by Interactive Oil Paint Filtering</h3><p></p>Computers &amp; Graphics, 2016,&nbsp;<a href="http://vcg.isti.cnr.it/cgf/winner.php?year=2016">CGF Cover Contest 2016 (Runner-up)</a><p><small>Amir Semmo, Daniel Limberger, Jan Eric Kyprianidis, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2016-cgf-oilpaint-stylization">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2016-cgf-oilpaint-stylization">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1016/j.cag.2015.12.001">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Amir_Semmo/publication/289694790/inline/jsViewer/5a38e88a458515919e727ede">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2016-cgf-oilpaint-stylization"><p>An interactive system for transforming images into an oil paint look is presented. First, dominant colors from an input image are derived for feature-aware recolorization and quantization to conform with a global color palette. Afterwards, it employs non-linear filtering based on the smoothed structure adapted to the main feature contours of the quantized image to synthesize a paint texture in real-time. Furthermore, a generalized brush-based painting interface is introduced that operates within parameter spaces to locally adjust the level of abstraction of the filtering effects.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2016-cgf-oilpaint-stylization"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="semmo2016-oilpaint-stylization.bib" href="/bibliography/semmo2016-oilpaint-stylization.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2016-cgf-oilpaint-stylization" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2016-cgf-oilpaint-stylization">@article{semmo2016-oilpaint-stylization,
  author = {Semmo, Amir and Limberger, Daniel and Kyprianidis, Jan Eric and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Image Stylization by Interactive Oil Paint Filtering},
  journal = {Computers \&amp; Graphics},
  year = {2016},
  volume = {55},
  pages = {157--171},
  doi = {10.1016/j.cag.2015.12.001}
}
</pre></div></div></div></div><div class="row" id="2015-cgvc-natural-metaphors"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><a class="thumbnail flickr" href="https://www.flickr.com/photos/131006004@N06/sets/72157663043933623/" data-photoset-id="72157663043933623"><span class="badge bg-primary position-absolute top-0 start-0">Flickr</span></a><img class="img-fluid rounded" width="768" height="768" src="/images/2015-cgvc-natural-metaphors.webp" alt="Thumbnail of Natural Phenomena as Metaphors for Visualization of Trend Data in Interactive Software Maps"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Natural Phenomena as Metaphors for Visualization of Trend Data in Interactive Software Maps</h3><p></p>Proc. EG Computer Graphics and Visual Computing (CGVC), 2015<p><small>Hannes Würfel, Matthias Trapp, Daniel Limberger, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2015-cgvc-natural-metaphors">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2015-cgvc-natural-metaphors">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.2312/cgvc.20151246">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Matthias_Trapp/publication/281347949/inline/jsViewer/55ffbd6508aeafc8ac8ba169">Paper</a></p><div class="collapse abstract" data-bs-target id="abstract-2015-cgvc-natural-metaphors"><p>This work explores the suitability of rendering natural phenomena in Software maps for effective communication of changes as well as trends. Therefore, Unreal Engine 4 is prototypically used to render Software maps and natural phenomena, such as fire, clouds, smoke, rain, rust, or shininess in real-time. Trend data is automatically computed by hierarchically accumulating as well as analyzing the underlying software metrics, and is mapped to the additional visual variables.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2015-cgvc-natural-metaphors"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="wuerfel2015-natural-metaphors.bib" href="/bibliography/wuerfel2015-natural-metaphors.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2015-cgvc-natural-metaphors" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2015-cgvc-natural-metaphors">@inproceedings{wuerfel2015-natural-metaphors,
  author = {W{\&quot;u}rfel, Hannes and Trapp, Matthias and Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Natural Phenomena as Metaphors for Visualization of Trend Data in Interactive Software Maps},
  booktitle = {Computer Graphics and Visual Computing (CGVC)},
  year = {2015},
  series= {CGVC~'15},
  publisher = {The Eurographics Association},
  pages = {69--76},
  doi = {10.2312/cgvc.20151246},
  isbn = {978-3-905674-94-1},
}
</pre></div></div></div></div><div class="row" id="2015-cae-oilpaint-stylization"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><img class="img-fluid rounded" width="768" height="768" src="/images/2015-cae-oil-paint-stylization-using-color-palettes.webp" alt="Thumbnail of Image Stylization by Oil Paint Filtering using Color Palettes"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Image Stylization by Oil Paint Filtering using Color Palettes</h3><p></p>Proc. EG Computational Aesthetics (CAe), 2015,&nbsp;<a href="http://expressive.richardt.name/2015/Prizes">Best Paper</a><p><small>Amir Semmo, Daniel Limberger, Jan Eric Kyprianidis, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2015-cae-oilpaint-stylization">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2015-cae-oilpaint-stylization">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.2312/exp.20151188">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Amir_Semmo/publication/277531015/inline/jsViewer/556c35b208aeccd7773a2f85">Paper</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=T65gbk8Ruk4">Video</a></p><div class="collapse abstract" data-bs-target id="abstract-2015-cae-oilpaint-stylization"><p>This paper presents an approach for transforming images into an oil paint look. A color quantization scheme is proposed that performs feature-aware recolorization using the dominant colors of the input image. In addition, an approach for real-time computation of paint textures is presented that builds on the smoothed structure adapted to the main feature contours of the quantized image. The stylization technique leads to homogeneous outputs in the color domain and enables creative control over the visual output, such as color adjustments and per-pixel parametrizations by means of interactive painting.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2015-cae-oilpaint-stylization"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="semmo2015-oilpaint-stylization.bib" href="/bibliography/semmo2015-oilpaint-stylization.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2015-cae-oilpaint-stylization" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2015-cae-oilpaint-stylization">@inproceedings{semmo2015-oilpaint-stylization,
  author = {Semmo, Amir and Limberger, Daniel and Kyprianidis, Jan Eric and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Image Stylization by Oil Paint Filtering using Color Palettes},
  booktitle = {Proceedings of the Workshop on Computational Aesthetics},
  year = {2015},
  series = {CAE~'15},
  publisher = {Eurographics Association},
  pages = {149--158},
  doi = {10.2312/exp.20151188},
}
</pre></div></div></div></div><div class="row" id="2014-expressive-parameter-painting"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><a class="thumbnail flickr" href="https://www.flickr.com/photos/131006004@N06/sets/72157650124474077/" data-photoset-id="72157650124474077"><span class="badge bg-primary position-absolute top-0 start-0">Flickr</span></a><img class="img-fluid rounded" width="768" height="768" src="/images/2014-expressive-painting-per-pixel-parametrization.webp" alt="Thumbnail of Painting Per-Pixel Parametrization for Interactive Image Filtering"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Painting Per-Pixel Parametrization for Interactive Image Filtering</h3><p></p>ACM/EG Expressive Posters, 2014<p><small>Daniel Limberger and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2014-expressive-parameter-painting">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2014-expressive-parameter-painting">BibTeX</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/313549904/inline/jsViewer/589dc04caca272046aa9042e">Poster</a></p><div class="collapse abstract" data-bs-target id="abstract-2014-expressive-parameter-painting"><p>This work presents a photo-editing method that enables per-pixel parameter manipulation of image filtering by means of interactive painting. Predefined or custom image filters are exposed to the user, as a parametrizable composition of image operations. Brushes, as sequences of actions mapping user inputs (in terms of brush shape, flow, pressure, etc.) to arbitrary functions or convolution operators, are used to draw within the parameter space. It demonstrates how interactive painting can be used to, e.g., locally tweak parametrization and, furthermore, provides a blueprint for an collaborative photo-editing platform.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2014-expressive-parameter-painting"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2014-parameter-painting.bib" href="/bibliography/limberger2014-parameter-painting.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2014-expressive-parameter-painting" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2014-expressive-parameter-painting">@misc{limberger2014-parameter-painting,
  author = {Limberger, Daniel and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Painting Per-Pixel Parametrization for Interactive Image Filtering},
  year = {2014},
  note = {Poster presented at the Expressive 2014 Poster Session, August 8, Fletcher Challenge Theatre, Harbour Centre},
}
</pre></div></div></div></div><div class="row" id="2013-web3d-web-based-swmaps"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><a class="thumbnail flickr" href="https://www.flickr.com/photos/131006004@N06/sets/72157650179270797/" data-photoset-id="72157650179270797"><span class="badge bg-primary position-absolute top-0 start-0">Flickr</span></a><img class="img-fluid rounded" width="768" height="768" src="/images/2013-web3d-interactive-software-maps.webp" alt="Thumbnail of Interactive Software Maps for Web-Based Source Code Analysis"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Interactive Software Maps for Web-Based Source Code Analysis</h3><p></p>Proc. ACM Int. Conf. on Web3D Technology (Web3D), 2013<p><small>Daniel Limberger, Benjamin Wasty, Jonas Trümper, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2013-web3d-web-based-swmaps">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2013-web3d-web-based-swmaps">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.1145/2466533.2466550">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/262408378/inline/jsViewer/589dbde3aca272046aa8ffa7">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/331556350/inline/jsViewer/5c7fed69458515831f8aff6a">Slides</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=AaHJRVQ3Z1E">Video</a></p><div class="collapse abstract" data-bs-target id="abstract-2013-web3d-web-based-swmaps"><p>Software maps&mdash;linking 2.5D treemaps, software system structure, and performance indicators&mdash;are commonly used to support informed decision making in software-engineering processes. In this paper a web-based rendering system for software maps that achieves both fast client-side page load time and interactive frame rates even with large software maps is presented. The page load time is significantly reduced by efficiently encoding hierarchy and geometry data for the net transport.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2013-web3d-web-based-swmaps"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2013-interactive.bib" href="/bibliography/limberger2013-interactive.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2013-web3d-web-based-swmaps" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2013-web3d-web-based-swmaps">@inproceedings{limberger2013-interactive,
  author = {Limberger, Daniel and Wasty, Benjamin and Tr{\&quot;u}mper, Jonas and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Interactive Software Maps for Web-based Source Code Analysis},
  booktitle = {Proceedings of the 18th International Conference on 3D Web Technology},
  year = {2013},
  series = {Web3D~'13},
  publisher = {ACM},
  pages = {91--98},
  doi = {10.1145/2466533.2466550},
  isbn = {978-1-450321-33-4},
}
</pre></div></div></div></div><div class="row" id="2012-vmv-sky-phenomena"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><a class="thumbnail flickr" href="https://www.flickr.com/photos/131006004@N06/sets/72157650186586300/" data-photoset-id="72157650186586300"><span class="badge bg-primary position-absolute top-0 start-0">Flickr</span></a><img class="img-fluid rounded" width="768" height="768" src="/images/2012-vmv-day-and-night-sky.webp" alt="Thumbnail of Single-Pass Rendering of Day and Night Sky Phenomena"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Single-Pass Rendering of Day and Night Sky Phenomena</h3><p></p>Proc. EG Int. Workshop on Vision, Modeling, and Visualization (VMV), 2012<p><small>Daniel Müller (now Limberger), Juri Engel, and Jürgen Döllner</small></p><p><a data-bs-toggle="collapse" href="#abstract-2012-vmv-sky-phenomena">Abstract</a>&ensp;|&ensp;<a data-bs-toggle="collapse" href="#bibtex-2012-vmv-sky-phenomena">BibTeX</a>&ensp;|&ensp;<a href="https://doi.org/10.2312/PE/VMV/VMV12/055-062">DOI</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/287031803/inline/jsViewer/58db7a24a6fdccca1c9488b3">Paper</a>&ensp;|&ensp;<a href="https://www.researchgate.net/profile/Daniel_Limberger/publication/331556201/inline/jsViewer/5c7feeb5299bf1268d403c6d">Slides</a>&ensp;|&ensp;<a href="https://www.youtube.com/watch?v=t8ibsEl0kAI">Video</a>&ensp;|&ensp;<a href="https://github.com/cgcostume/osghimmel">Source Code</a></p><div class="collapse abstract" data-bs-target id="abstract-2012-vmv-sky-phenomena"><p>This paper presents techniques for astronomical based, real-time rendering of skies as seen from low altitudes on earth, in respect to location, date, and time. The techniques allow for composing an atmosphere with sun, multiple cloud layers, moon, bright stars, and Milky Way, into a holistic sky with unprecedented level of detail and diversity. GPU generated, viewpoint-aligned billboards are used to render stars with approximated color, brightness, and scintillations. A similar approach is used to synthesize the moon considering lunar phase, earthshine, shading, and lunar eclipses.</p></div><div class="collapse bibtex" data-bs-target id="bibtex-2012-vmv-sky-phenomena"><div class="position-absolute top-0 end-0"><a class="btn btn-sm" type="button" download="limberger2012-sky-phenomena.bib" href="/bibliography/limberger2012-sky-phenomena.bib">Download</a><button class="btn btn-sm btn-clipboard" type="button" data-clipboard-target="#bibtex-data-2012-vmv-sky-phenomena" data-clipboard-action="copy">Copy to Clipboard</button></div><div class="card-body"><pre id="bibtex-data-2012-vmv-sky-phenomena">@inproceedings{limberger2012-sky-phenomena,
  author = {M{\&quot;u}ller, Daniel and Engel, Juri and D{\&quot;o}llner, J{\&quot;u}rgen},
  title = {Single-Pass Rendering of Day and Night Sky Phenomena},
  booktitle = {Proceedings of the Vision, Modeling, and Visualization Workshop},
  year = {2012},
  series = {VMV~'12},
  publisher = {Eurographics Association},
  pages = {55--62},
  doi = {10.2312/PE/VMV/VMV12/055-062},
  isbn = {978-3-905673-95-1},
}
</pre></div></div></div></div><hr class="row separator"><div class="row" id="2012-mt-sky-rendering"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><a class="thumbnail flickr" href="https://www.flickr.com/photos/131006004@N06/sets/72157650186586300/" data-photoset-id="72157650186586300"><span class="badge bg-primary position-absolute top-0 start-0">Flickr</span></a><img class="img-fluid rounded" width="768" height="768" src="/images/2012-mt-sky-rendering.webp" alt="Thumbnail of Photorealistisches Rendering atmosphärischer Effekte in geovirtuellen 3D-Umgebungen in Echtzeit"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Photorealistisches Rendering atmosphärischer Effekte in geovirtuellen 3D-Umgebungen in Echtzeit</h3><p></p>Master's Thesis in IT-Systems Engineering, Hasso Plattner Institute, 2012<p><small>Daniel Müller (now Limberger)</small></p><p><a data-bs-toggle="collapse" href="#abstract-2012-mt-sky-rendering">Abstract</a>&ensp;|&ensp;<a href="resources/2012 – Mueller (now Limberger) – Photorealistisches Rendering atmosphaerischer Effekte in geovirtuellen 3D-Umgebungen in Echtzeit.pdf">Master's Thesis [de]</a>&ensp;|&ensp;<a href="https://github.com/hpicgs/osghimmel">Source Code</a></p><div class="collapse abstract" data-bs-target id="abstract-2012-mt-sky-rendering"><p>The document was written and is available in German language only.<br><br>In this work we present a system for image-synthesis of atmospheric effects in virtual 3d environments. It allows realtime rendering of dynamic, high quality environments for background composition (background scenery) for a variety of applications not only in video-games and simulators (e.g., Flight- or vehicle-simulators), but also for architectural and historical visualizations. To ensure ease of integration, only the background associated phenomena are taken into account. Thereby a texture-based, and a simulation-based approach are presented. The texture-based approach targets the imitation of any environment and uses wellknown, texture-based methods with hardly any creative limitations. They are expandable and ideal for applications where, in resprect to the rendering performance, only low capacities can be allocated. The simulation-based, astrophysical approach, in contrast, is based on astronomical algorithms and astrophysical observations. The new models and methods used within this approach, provide the conceptual focus of this work. Both approaches are optimized for rendering dynamic day-night cycles within a single rendering pass and without subsequent processing. They are integrated in a large representative rendering system (OpenSceneGraph). Detailed performance measurements in different scenarios and quality levels show that the system has little effect on overall rendering-speed.</p></div></div></div><div class="row" id="2009-bt-pencil-synthesis"><div class="col-lg-2 col-sm-3"><div class="thumbnail position-relative"><a class="thumbnail flickr" href="https://www.flickr.com/photos/131006004@N06/sets/72157690157643673/" data-photoset-id="72157690157643673"><span class="badge bg-primary position-absolute top-0 start-0">Flickr</span></a><img class="img-fluid rounded" width="768" height="768" src="/images/2009-bt-pencil-synthesis.webp" alt="Thumbnail of Computergenerierte Bleistiftzeichnungen von 3D-Stadtmodellen"></div></div><div class="d-block d-sm-none mb-3 col-12"></div><div class="col-lg-10 col-sm-9"><h3>Computergenerierte Bleistiftzeichnungen von 3D-Stadtmodellen</h3><p></p>Bachelor's Thesis in IT-Systems Engineering, Hasso Plattner Institute, 2009<p><small>Daniel Müller (now Limberger)</small></p><p><a data-bs-toggle="collapse" href="#abstract-2009-bt-pencil-synthesis">Abstract</a>&ensp;|&ensp;<a href="resources/2009 – Mueller (now Limberger) – Computergenerierte Bleistiftzeichnungen von 3D-Stadtmodellen.pdf">Bachelor's Thesis [de]</a></p><div class="collapse abstract" data-bs-target id="abstract-2009-bt-pencil-synthesis"><p>This work summarizes techniques for 3D-image synthesis of pencil or crayon drawings of virtual 3D-city-models in real-time. The document was written and is available in German language only.<br><br>Diese Arbeit befasst sich mit der Erstellung von Bleistiftzeichnungen dreidimensionaler Modelle in Echtzeit und prüft die Anwendbarkeit auf virtuelle 3D-Stadtmodelle. Bisherige Verfahren gehen kaum auf stilprägende subjektive Einflüsse der Zeichner ein. So werden stilrelevante Maßnahmen wie weiche Schatten und Lichteinflüsse durch Umgebungsverdeckung häufig vernachlässigt. Nach einer kurzen Zusammenfassung bisheriger Ansätze zur Nachahmung von Bleistiftzeichnungen, werden effiziente Implementierung für Konturdarstellung und Krümmungsapproximation zur Schraffur vorgestellt. Da die meisten Berechnungen diskretisiert im Bildraum vorgenommen werden, entstehen beim Rendern komplexer 3D-Stadtmodelle störende, mit der Tiefe zunehmende Artefakte. Zur Abschwächung dieser Störfaktoren werden praktische Lösungen wie stilkonforme Tiefenfokussierung diskutiert.</p></div></div></div></section><section class="container" id="footer"><footer><div class="row text-center"><div class="col-12"><p class="mt-5 mb-1">&copy; 2015&thinsp;&ndash;&thinsp;2022 Limberger Daniel</p><small class="mt-0 mb-5"><span class="text-muted">This website was last updated on 11/25/2022</span>&ensp;|&ensp;<a class="text-muted" href="privacy-policy.html">Privacy Policy</a>&ensp;|&ensp;<a class="text-muted" href="https://github.com/cgcostume/portfolio/">Source Code (GitHub)</a></small></div></div><data hidden value="4239525">revision</data></footer></section></body><script src="/bootstrap.js"></script><script src="/scripts.js"></script></html>